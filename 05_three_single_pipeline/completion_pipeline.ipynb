{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b978a284-f629-4632-8cfc-e8706a3fa107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import (\n",
    "    GPT_KEY, CLAUDE_KEY, LLMAPI_KEY,\n",
    "    GPT_MODEL, CLAUDE_MODEL, LLMAPI_MODEL,\n",
    "    CSV_PATH, FIND_DIR, COMP_DIR,\n",
    "    MAX_TOKENS, TEMPERATURE\n",
    ")\n",
    "from src.llm_clients import GPTClient, ClaudeClient, LlamaAPIClient\n",
    "from src.schemas import ResolvedSentence, CompletionDoc, PartialResolved\n",
    "from src.prompts import get_prompt\n",
    "from src.json_utils import parse_or_fix\n",
    "from src.utils import split_sents, ensure_dir_exists\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import tqdm.auto as tqdm\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f3e9f1-bbef-41f4-8c0d-a95026531e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output directory\n",
    "ensure_dir_exists(COMP_DIR)\n",
    "\n",
    "# Load Abstract\n",
    "df_abs = pd.read_csv(CSV_PATH, usecols=[0, 1], header=0, names=[\"pmid\", \"abstract\"])\n",
    "ABS_CACHE = df_abs.set_index(\"pmid\")[\"abstract\"].to_dict()\n",
    "\n",
    "# Index the finding sentence for phase one loading\n",
    "def load_findings(tag: str) -> dict[str, set[int]]:\n",
    "    out = {}\n",
    "    with open(f\"{FIND_DIR}/{tag}.jsonl\", \"r\", encoding=\"utf-8\") as fr:\n",
    "        for line in fr:\n",
    "            j = json.loads(line)\n",
    "            out[j[\"pmid\"]] = set(j[\"finding_ids\"])\n",
    "    return out\n",
    "\n",
    "find_ids = {t: load_findings(t) for t in [\"gpt4o\", \"claude\", \"llama\"]}\n",
    "\n",
    "# Initialize LLM Client\n",
    "clients = {\n",
    "    \"gpt4o\": GPTClient(model=GPT_MODEL, key=GPT_KEY),\n",
    "    \"claude\": ClaudeClient(model=CLAUDE_MODEL, key=CLAUDE_KEY),\n",
    "    \"llama\": LlamaAPIClient(model=LLMAPI_MODEL, key=LLMAPI_KEY)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7491970c-ca29-4c4e-b687-e2995497ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prompt\n",
    "system_prompt, fewshot = get_prompt(\"completion\")\n",
    "\n",
    "def build_msgs(pmid: str, sid: int, sent: str, context: str) -> list[dict]:\n",
    "    user = (\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Sentence [{sid}]:\\n{sent}\\n\\n\"\n",
    "        \"Return JSON:\"\n",
    "    )\n",
    "    return fewshot + [{\"role\": \"user\", \"content\": user}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f151ca-db05-4b8e-a5af-9cffc4dbbdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_completion(model_tag: str):\n",
    "    cli = clients[model_tag]\n",
    "    out_path = f\"{COMP_DIR}/{model_tag}.jsonl\"\n",
    "    fail_path = f\"{COMP_DIR}/{model_tag}.fail.txt\"\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as fw, \\\n",
    "         open(fail_path, \"w\", encoding=\"utf-8\") as fail_log:\n",
    "\n",
    "        for pmid_str, ids in tqdm.tqdm(find_ids[model_tag].items(), desc=f\"{model_tag}\"):\n",
    "            pmid_int = int(pmid_str)\n",
    "            if pmid_int not in ABS_CACHE:\n",
    "                continue\n",
    "\n",
    "            context = ABS_CACHE[pmid_int]\n",
    "            sents = split_sents(context)\n",
    "            completed = []\n",
    "\n",
    "            for sid in sorted(ids):\n",
    "                if sid < 0 or sid >= len(sents):\n",
    "                    continue\n",
    "\n",
    "                msgs = build_msgs(pmid_str, sid, sents[sid], context)\n",
    "                try:\n",
    "                    raw = cli.run(msgs, task_id=f\"{pmid_str}-{sid}\")\n",
    "                    part_list = parse_or_fix(raw, cli, msgs, target_class=List[PartialResolved])\n",
    "                    for part in part_list:\n",
    "                        completed.append(\n",
    "                            ResolvedSentence(\n",
    "                                id=part.id,\n",
    "                                original=sents[part.id] if part.id < len(sents) else sents[sid],\n",
    "                                resolved=part.resolved\n",
    "                            )\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(f\"[{model_tag}][{pmid_str}][{sid}] failed → {e}\")\n",
    "                    fail_log.write(f\"{pmid_str}\\t{sid}\\t{e}\\n\")\n",
    "                    continue\n",
    "\n",
    "            doc = CompletionDoc(pmid=pmid_str, sentences=completed)\n",
    "            fw.write(doc.model_dump_json(ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"{model_tag} sentence complete -> {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df87b046-7844-4752-b9d0-2f19882f5309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b495abe00d46fba28693db64f42a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gpt4o:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retry 1] Invalid JSON: Parsed JSON is empty or invalid content\n",
      "-> Raw output: {} \n",
      "[Retry 2] Invalid JSON: Parsed JSON is empty or invalid content\n",
      "-> Raw output: {} \n",
      "[Retry 3] Invalid JSON: Parsed JSON is empty or invalid content\n",
      "-> Raw output: {} \n",
      "[gpt4o][16133256][11] failed ->Final JSON parse failed: Parsed JSON is empty or invalid content\n",
      "gpt4o sentence complete -> completion/gpt4o.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13c87be74704a5d95cb54b108d4bfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "claude:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retry 1] Invalid JSON: No valid JSON object found. Sample: [}...\n",
      "-> Raw output: [] \n",
      "[Retry 2] Invalid JSON: No valid JSON object found. Sample: [}...\n",
      "-> Raw output: [] \n",
      "[Retry 3] Invalid JSON: No valid JSON object found. Sample: [}...\n",
      "-> Raw output: [] \n",
      "[claude][33095090][3] failed ->Final JSON parse failed: No valid JSON object found. Sample: [}...\n",
      "[Retry 1] Invalid JSON: Unterminated string starting at: line 1 column 23 (char 22)\n",
      "-> Raw output: [{\"id\": 3, \"resolved\": \"Whole cell viscoelasticity depends strongly on time, frequency, and strain.}, {\"id\": 3, \"resolved\": \"Comparison of wild-type and mutant strains under identical conditions generally produced significant differences in whole cell viscoelasticity.\"}] \n",
      "[Retry 1] Invalid JSON: Unterminated string starting at: line 1 column 23 (char 22)\n",
      "-> Raw output: [{\"id\": 2, \"resolved\": \"Eighty-six percent of spontaneous splenic arteriovenous fistulas occur in women.}, {\"id\": 2, \"resolved\": \"Fifty-five percent of spontaneous splenic arteriovenous fistulas are associated with a preexisting splenic artery aneurysm.}] \n",
      "[Retry 1] Invalid JSON: Unterminated string starting at: line 1 column 23 (char 22)\n",
      "-> Raw output: [{\"id\": 9, \"resolved\": \"One hundred sixty-five out of two hundred forty-five patient advocacy organizations (67.3%) reported receiving industry funding.}, {\"id\": 9, \"resolved\": \"Nineteen out of one hundred sixty patient advocacy organizations (11.9%) received more than half of their funding from ind ...\n",
      "[Retry 1] Invalid JSON: Unterminated string starting at: line 1 column 24 (char 23)\n",
      "-> Raw output: [{\"id\": 10, \"resolved\": \"Among the subset of patient advocacy organizations that received industry funding, the median amount was $50,000, with an interquartile range of $15,000 to $200,000.}, {\"id\": 10, \"resolved\": \"The median proportion of industry support for patient advocacy organizations derive ...\n",
      "[Retry 1] Invalid JSON: Unterminated string starting at: line 1 column 23 (char 22)\n",
      "-> Raw output: [{\"id\": 5, \"resolved\": \"83.2% of the participants suffered from poor sleep quality.}, {\"id\": 5, \"resolved\": \"One-half of the participants had moderate or excessive sleepiness.\"}] \n",
      "[Retry 1] Invalid JSON: Unterminated string starting at: line 1 column 23 (char 22)\n",
      "-> Raw output: [{\"id\": 7, \"resolved\": \"Simple models substantially underestimate the degree of divergence between sequences.}, {\"id\": 7, \"resolved\": \"The underestimation of divergence between sequences by simple models was more pronounced on the internal branches of the tree.\"}] \n",
      "[Retry 1] Invalid JSON: Unterminated string starting at: line 1 column 23 (char 22)\n",
      "-> Raw output: [{\"id\": 3, \"resolved\": \"On the oleic acid diet, the mean serum values for the entire group for total cholesterol were 4.46 ± 0.66 mmol per liter.}, {\"id\": 3, \"resolved\": \"On the oleic acid diet, the mean serum values for the entire group for low-density lipoprotein (LDL) cholesterol were 2.67 ± 0.54 ...\n",
      "claude sentence complete -> completion/claude.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cb78f6f21c442c97ce6eaa893a0238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retry 1] Invalid JSON: Expecting ',' delimiter: line 1 column 77 (char 76)\n",
      "-> Raw output: [{\"id\": 12, \"resolved\": \"Deactivation of IR channels was also slowed by Rb+.\")] \n",
      "llama sentence complete -> completion/llama.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Run models\n",
    "run_completion(\"gpt4o\")\n",
    "run_completion(\"claude\")\n",
    "run_completion(\"llama\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
