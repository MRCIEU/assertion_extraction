{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b31ce8-15cd-47a0-b473-93c770172363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "ASSERTION_DIR = \"assertion\"\n",
    "OUT_DIR = \"eval\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e2a798-bed2-4d99-800b-a08481aa3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full UMLS predicate list\n",
    "UMLS_PREDICATES = set([\n",
    "    \"affects\", \"associated with\", \"causes\", \"complicates\", \"contraindicated with\",\n",
    "    \"disrupts\", \"inhibits\", \"interacts with\", \"manages\", \"precedes\",\n",
    "    \"prevents\", \"produces\", \"promotes\", \"stimulates\", \"treats\",\n",
    "    \"increases\", \"decreases\", \"enhances\", \"induces\", \"leads to\",\n",
    "    \"negatively regulates\", \"positively regulates\", \"regulates\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4980df1d-403f-4710-8513-2825e4f1a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load assertions\n",
    "def load_assertions(model_tag):\n",
    "    data = []\n",
    "    with open(os.path.join(ASSERTION_DIR, f\"{model_tag}.jsonl\"), encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            pmid = obj['pmid']\n",
    "            for a in obj['assertion']:\n",
    "                row = {'pmid': pmid, 'model': model_tag, **a}\n",
    "                data.append(row)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load all\n",
    "dfs = [load_assertions(tag) for tag in [\"gpt4o\", \"claude\", \"llama\"]]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Load SpaCy model for POS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af1d124-d7d5-472b-95b8-cbd3d8176041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS check for subject/object\n",
    "def check_np_type(text):\n",
    "    doc = nlp(text)\n",
    "    root = [token for token in doc if token.head == token]\n",
    "    if not root:\n",
    "        return \"unknown\"\n",
    "    pos = root[0].pos_\n",
    "    if pos in [\"NOUN\", \"PROPN\"]:\n",
    "        return \"noun\"\n",
    "    elif pos == \"VERB\":\n",
    "        return \"verb\"\n",
    "    elif pos == \"ADJ\":\n",
    "        return \"adjective\"\n",
    "    elif pos == \"NUM\":\n",
    "        return \"numeric\"\n",
    "    elif pos == \"PRON\":\n",
    "        return \"pronoun\"\n",
    "    elif pos == \"ADV\":\n",
    "        return \"adverb\"\n",
    "    elif pos == \"AUX\":\n",
    "        return \"auxiliary\"\n",
    "    else:\n",
    "        return \"phrase\"\n",
    "\n",
    "# Predicate match quality and similarity\n",
    "def predicate_match(pred):\n",
    "    pred_low = pred.lower().strip()\n",
    "    if pred_low in UMLS_PREDICATES:\n",
    "        return \"exact\"\n",
    "    for std in UMLS_PREDICATES:\n",
    "        sim = SequenceMatcher(None, pred_low, std).ratio()\n",
    "        if sim >= 0.8:\n",
    "            return \"similar\"\n",
    "    return \"non_umls\"\n",
    "\n",
    "def predicate_topk(pred, topk=3):\n",
    "    pred_low = pred.lower().strip()\n",
    "    scores = [(p, SequenceMatcher(None, pred_low, p).ratio()) for p in UMLS_PREDICATES]\n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True)[:topk]\n",
    "\n",
    "# Condition type analysis\n",
    "def condition_type(cond):\n",
    "    if not cond:\n",
    "        return \"none\"\n",
    "    cond = cond.lower()\n",
    "    if any(x in cond for x in [\"patients\", \"subjects\", \"mice\", \"cohort\"]):\n",
    "        return \"population\"\n",
    "    elif any(x in cond for x in [\"in vitro\", \"in vivo\", \"experiment\", \"study\"]):\n",
    "        return \"experiment\"\n",
    "    elif any(x in cond for x in [\"if\", \"when\", \"under\", \"provided\"]):\n",
    "        return \"logical\"\n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da805aaf-4949-4d50-b6f9-721e05dc1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply checks\n",
    "df[\"subj_type\"] = df[\"subject\"].map(check_np_type)\n",
    "df[\"obj_type\"] = df[\"object\"].map(check_np_type)\n",
    "df[\"predicate_match\"] = df[\"predicate\"].map(predicate_match)\n",
    "df[\"predicate_top3\"] = df[\"predicate\"].map(lambda x: predicate_topk(x))\n",
    "df[\"condition_type\"] = df[\"condition\"].fillna(\"\").map(condition_type)\n",
    "\n",
    "# Save detailed\n",
    "df.to_csv(f\"{OUT_DIR}/assertion_detailed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64760706-a7fd-46a9-bbf2-4264f8b592cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Assertion Evaluation Summary ===\n",
      "                                      predicate_match  \\\n",
      "model                                                   \n",
      "claude  [(non_umls, 284), (exact, 49), (similar, 28)]   \n",
      "gpt4o   [(non_umls, 193), (exact, 86), (similar, 26)]   \n",
      "llama   [(non_umls, 303), (exact, 29), (similar, 25)]   \n",
      "\n",
      "                                                subj_type  \\\n",
      "model                                                       \n",
      "claude  [(noun, 321), (verb, 34), (numeric, 3), (adjec...   \n",
      "gpt4o   [(noun, 277), (verb, 23), (phrase, 2), (adject...   \n",
      "llama   [(noun, 324), (verb, 20), (numeric, 6), (phras...   \n",
      "\n",
      "                                                 obj_type  \\\n",
      "model                                                       \n",
      "claude  [(noun, 283), (verb, 30), (phrase, 27), (adjec...   \n",
      "gpt4o   [(noun, 254), (verb, 25), (phrase, 14), (adjec...   \n",
      "llama   [(noun, 277), (verb, 30), (phrase, 21), (adjec...   \n",
      "\n",
      "                                           condition_type  \n",
      "model                                                      \n",
      "claude  [(other, 187), (none, 143), (logical, 15), (po...  \n",
      "gpt4o   [(other, 151), (none, 130), (logical, 11), (po...  \n",
      "llama   [(none, 194), (other, 143), (logical, 14), (po...  \n",
      "\n",
      "Saved evaluation results to eval/assertion_*.csv\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "summary = df.groupby(\"model\").agg({\n",
    "    \"predicate_match\": lambda x: Counter(x).most_common(),\n",
    "    \"subj_type\": lambda x: Counter(x).most_common(),\n",
    "    \"obj_type\": lambda x: Counter(x).most_common(),\n",
    "    \"condition_type\": lambda x: Counter(x).most_common()\n",
    "})\n",
    "\n",
    "summary.to_csv(f\"{OUT_DIR}/assertion_summary.csv\")\n",
    "print(\"\\n=== Assertion Evaluation Summary ===\")\n",
    "print(summary)\n",
    "print(\"\\nSaved evaluation results to eval/assertion_*.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
