{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d554803-db66-4af6-aab1-869d1b31d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import (\n",
    "    GPT_KEY, CLAUDE_KEY, LLMAPI_KEY,\n",
    "    GPT_MODEL, CLAUDE_MODEL, LLMAPI_MODEL,\n",
    "    COMP_DIR, ASSR_DIR,\n",
    "    MAX_TOKENS, TEMPERATURE\n",
    ")\n",
    "from src.llm_clients import GPTClient, ClaudeClient, LlamaAPIClient\n",
    "from src.schemas import Assertion, AssertionDoc\n",
    "from src.prompts import get_prompt\n",
    "from src.json_utils import parse_or_fix\n",
    "from src.utils import ensure_dir_exists, start_timer, log_tokens, save_stats_to_csv, estimate_tokens\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import tqdm.auto as tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a1cda9-580c-4bb9-9af1-e3c539f637d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output repository\n",
    "ensure_dir_exists(ASSR_DIR)\n",
    "\n",
    "# Load the second-stage output (completion).\n",
    "def load_completions(model_tag: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with open(f\"{COMP_DIR}/{model_tag}.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            for s in obj[\"sentences\"]:\n",
    "                rows.append({\n",
    "                    \"pmid\": obj[\"pmid\"],\n",
    "                    \"id\": s[\"id\"],\n",
    "                    \"sentence\": s[\"resolved\"]\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def load_completions(tag: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with open(f\"{COMP_DIR}/{tag}.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            for s in obj[\"sentences\"]:\n",
    "                rows.append({\n",
    "                    \"pmid\": obj[\"pmid\"],\n",
    "                    \"id\": s[\"id\"],\n",
    "                    \"sentence\": s[\"resolved\"]\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Initialize LLM Client\n",
    "clients = {\n",
    "    \"gpt4o\": GPTClient(model=GPT_MODEL, key=GPT_KEY),\n",
    "    \"claude\": ClaudeClient(model=CLAUDE_MODEL, key=CLAUDE_KEY),\n",
    "    \"llama\": LlamaAPIClient(model=LLMAPI_MODEL, key=LLMAPI_KEY)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66209e4a-e7f0-4a6c-a51c-9c7f7c4b21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt block\n",
    "system_prompt, fewshot = get_prompt(\"assertion\")\n",
    "\n",
    "def build_msgs(sent_id: int, sentence: str) -> list[dict]:\n",
    "    user = f\"Sentence [{sent_id}]: {sentence}\\nReturn JSON:\"\n",
    "    return fewshot + [{\"role\": \"user\", \"content\": user}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e89587-65f5-470d-852b-905cdbff2e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute assertion triplet extraction\n",
    "def run_assertion(tag: str):\n",
    "    cli = clients[tag]\n",
    "    out_path = f\"{ASSR_DIR}/{tag}.jsonl\"\n",
    "    open(out_path, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "    df = load_completions(tag)\n",
    "    grouped = df.groupby(\"pmid\")\n",
    "\n",
    "    start_timer(tag, \"assertion\")\n",
    "\n",
    "    for pmid, group in tqdm.tqdm(grouped, desc=f\"{tag} assertion\"):\n",
    "        assertions = []\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            sid = row[\"id\"]\n",
    "            sentence = row[\"sentence\"]\n",
    "\n",
    "            msgs = build_msgs(sid, sentence)\n",
    "\n",
    "            try:\n",
    "                raw = cli.run(msgs, task_id=f\"{tag}:{pmid}:{sid}\")\n",
    "                prompt_text = \"\\n\".join([m[\"content\"] for m in msgs])\n",
    "                estimated_tokens = estimate_tokens(prompt_text + raw)\n",
    "                log_tokens(tag, \"assertion\", estimated_tokens)\n",
    "\n",
    "                triple = parse_or_fix(raw, cli, msgs, target_class=Assertion)\n",
    "                assertions.append(triple)\n",
    "\n",
    "            except Exception as err:\n",
    "                print(f\"[{tag}][{pmid}][{sid}] failed → {err}\")\n",
    "                continue\n",
    "\n",
    "        if assertions:  # only write if non-empty\n",
    "            doc = AssertionDoc(\n",
    "                pmid=pmid,\n",
    "                assertion=assertions,\n",
    "                meta={\"model\": tag, \"timestamp\": datetime.now().isoformat()}\n",
    "            )\n",
    "            with open(out_path, \"a\", encoding=\"utf-8\") as fw:\n",
    "                fw.write(json.dumps(doc.model_dump(), ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    save_stats_to_csv(\"assertion\")\n",
    "    print(f\"{tag} extract assertion → {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde639ff-724f-499c-90c7-91cfcfa31373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f66ca3090294e649e05634abf6b045d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gpt4o assertion:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4o extract assertion → assertion/gpt4o.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f614f6321b4afcb6dfffe267f1d953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "claude assertion:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retry 1] Invalid JSON: ValidationError – 1 validation error for Assertion\n",
      "object\n",
      "  Field required [type=missing, input_value={'id': 12, 'subject': 'ex...predicate': 'increases'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "-> Raw output: {\"id\": 12, \"subject\": \"expression level of the apoptosis-related proteins Caspase 3 and PARP\", \"predicate\": \"increases\"} \n",
      "claude extract assertion → assertion/claude.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb78273d249145a4a3fc580e689fbe92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama assertion:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama extract assertion → assertion/llama.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Run models\n",
    "run_assertion(\"gpt4o\")\n",
    "run_assertion(\"claude\")\n",
    "run_assertion(\"llama\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
