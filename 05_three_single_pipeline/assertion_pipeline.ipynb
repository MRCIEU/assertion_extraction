{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d554803-db66-4af6-aab1-869d1b31d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import (\n",
    "    GPT_KEY, CLAUDE_KEY, LLMAPI_KEY,\n",
    "    GPT_MODEL, CLAUDE_MODEL, LLMAPI_MODEL,\n",
    "    COMP_DIR, ASSR_DIR,\n",
    "    MAX_TOKENS, TEMPERATURE\n",
    ")\n",
    "from src.llm_clients import GPTClient, ClaudeClient, LlamaAPIClient\n",
    "from src.schemas import Assertion, AssertionDoc\n",
    "from src.prompts import get_prompt\n",
    "from src.json_utils import parse_or_fix\n",
    "from src.utils import ensure_dir_exists\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a1cda9-580c-4bb9-9af1-e3c539f637d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output repository\n",
    "ensure_dir_exists(ASSR_DIR)\n",
    "\n",
    "# Load the second-stage output (completion).\n",
    "def load_completions(model_tag: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with open(f\"{COMP_DIR}/{model_tag}.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            for s in obj[\"sentences\"]:\n",
    "                rows.append({\n",
    "                    \"pmid\": obj[\"pmid\"],\n",
    "                    \"id\": s[\"id\"],\n",
    "                    \"sentence\": s[\"resolved\"]\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def load_completions(tag: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with open(f\"{COMP_DIR}/{tag}.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            for s in obj[\"sentences\"]:\n",
    "                rows.append({\n",
    "                    \"pmid\": obj[\"pmid\"],\n",
    "                    \"id\": s[\"id\"],\n",
    "                    \"sentence\": s[\"resolved\"]\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Initialize LLM Client\n",
    "clients = {\n",
    "    \"gpt4o\": GPTClient(model=GPT_MODEL, key=GPT_KEY),\n",
    "    \"claude\": ClaudeClient(model=CLAUDE_MODEL, key=CLAUDE_KEY),\n",
    "    \"llama\": LlamaAPIClient(model=LLMAPI_MODEL, key=LLMAPI_KEY)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66209e4a-e7f0-4a6c-a51c-9c7f7c4b21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt block\n",
    "system_prompt, fewshot = get_prompt(\"assertion\")\n",
    "\n",
    "def build_msgs(sent_id: int, sentence: str) -> list[dict]:\n",
    "    user = f\"Sentence [{sent_id}]: {sentence}\\nReturn JSON:\"\n",
    "    return fewshot + [{\"role\": \"user\", \"content\": user}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e89587-65f5-470d-852b-905cdbff2e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute assertion triplet extraction\n",
    "def run_assertion(tag: str):\n",
    "    cli = clients[tag]\n",
    "    out_path = f\"{ASSR_DIR}/{tag}.jsonl\"\n",
    "    fail_path = f\"{ASSR_DIR}/{tag}.fail.txt\"\n",
    "\n",
    "    df = load_completions(tag)\n",
    "    grouped = df.groupby(\"pmid\")\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as fw, \\\n",
    "         open(fail_path, \"w\", encoding=\"utf-8\") as fail_log:\n",
    "\n",
    "        for pmid, group in tqdm.tqdm(grouped, desc=f\"{tag} extraction\"):\n",
    "            assertions = []\n",
    "\n",
    "            for _, row in group.iterrows():\n",
    "                msgs = build_msgs(row[\"id\"], row[\"sentence\"])\n",
    "                try:\n",
    "                    raw = cli.run(msgs, task_id=f\"{pmid}-{row['id']}\")\n",
    "                    triple = parse_or_fix(raw, cli, msgs, target_class=Assertion)\n",
    "                    assertions.append(triple)\n",
    "                except Exception as err:\n",
    "                    print(f\"[{tag}][{pmid}][{row['id']}] failed â†’ {err}\")\n",
    "                    fail_log.write(f\"{pmid}\\t{row['id']}\\t{err}\\n\")\n",
    "                    continue\n",
    "\n",
    "            doc = AssertionDoc(pmid=pmid, assertion=assertions)\n",
    "            fw.write(doc.model_dump_json(ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"{tag} extract assertion -> {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde639ff-724f-499c-90c7-91cfcfa31373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0ae966647441bb9c0cf6523fceb44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gpt4o extraction:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4o extract assertion -> assertion/gpt4o.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b8f1f3e26647dba7fa11616a6d4b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "claude extraction:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retry 1] Invalid JSON: 1 validation error for Assertion\n",
      "object\n",
      "  Field required [type=missing, input_value={'id': 5, 'subject': 'sta...he simulated sequences'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "-> Raw output: {\"id\": 5, \"subject\": \"statistical models\", \"predicate\": \"perform well\", \"condition\": \"when there was no or limited purifying selection in the simulated sequences\"} \n",
      "[Retry 1] Invalid JSON: 1 validation error for Assertion\n",
      "object\n",
      "  Field required [type=missing, input_value={'id': 12, 'subject': 'ex...predicate': 'increases'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "-> Raw output: {\"id\": 12, \"subject\": \"expression level of the apoptosis-related proteins Caspase 3 and PARP\", \"predicate\": \"increases\"} \n",
      "[Retry 1] Invalid JSON: 1 validation error for Assertion\n",
      "object\n",
      "  Field required [type=missing, input_value={'id': 7, 'subject': 'the... the fourth experiment'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "-> Raw output: {\"id\": 7, \"subject\": \"the duration of evidence accumulation and processing between judgments\", \"predicate\": \"does not show substantial differences\", \"condition\": \"in the fourth experiment\"} \n",
      "[Retry 1] Invalid JSON: 1 validation error for Assertion\n",
      "object\n",
      "  Field required [type=missing, input_value={'id': 8, 'subject': 'rat...luorescein sodium flux'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "-> Raw output: {\"id\": 8, \"subject\": \"rat neurological function\", \"predicate\": \"is impaired\", \"condition\": \"accompanying with an increase of trans-endothelial electric resistance and fluorescein sodium flux\"} \n",
      "claude extract assertion -> assertion/claude.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47db85850fe24c0396528f52c0d3ca04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama extraction:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama extract assertion -> assertion/llama.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Run models\n",
    "run_assertion(\"gpt4o\")\n",
    "run_assertion(\"claude\")\n",
    "run_assertion(\"llama\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
