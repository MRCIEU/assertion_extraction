{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa539b1c-e9e2-4fe2-8427-25841edbd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beca3264-fe9d-4cac-85d4-373e76d5126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceLabelDataset(Dataset):\n",
    "    def __init__(self, jsonl_path):\n",
    "        self.data = []\n",
    "        with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                if len(item['sentences']) == len(item['labels']) and len(item['sentences']) > 0:\n",
    "                    self.data.append(item)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            'pmid': item.get('pmid', ''),\n",
    "            'sentences': item['sentences'],  # list of str\n",
    "            'labels': torch.tensor(item['labels'], dtype=torch.float)  # shape: (num_sent,)\n",
    "        }\n",
    "\n",
    "# collate: just batch multiple abstracts as list (no padding now)\n",
    "def collate_fn(batch):\n",
    "    return batch  # return list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f44f513-118e-44c7-aa5e-6bdf8c521487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID: 28982088\n",
      "Sentences: ['This work presents an integrated and multi-step approach for the recovery and/or application of the lignocellulosic fractions from corncob in the production of high value added compounds as xylo-oligosaccharides, enzymes, fermentable sugars, and lignin in terms of biorefinery concept.', 'For that, liquid hot water followed by enzymatic hydrolysis were used.', 'Liquid hot water was performed using different residence times (10-50min) and holding temperature (180-200°C), corresponding to severities (log(R']\n",
      "Labels: tensor([0., 0., 0.])\n",
      "PMID: 1733571\n",
      "Sentences: ['The proposed intermediate steps in the relationship between a diet-dependent increase in colonic bile acids and proliferation of colonic cells were studied in rats.', 'Male Wistar rats were fed diets supplemented with increasing amounts of steroids to increase the bile acid concentration of the colon.', 'After 2 weeks, in vivo colonic proliferation was measured using tritiated thymidine incorporation into DNA.', 'Luminal lytic activity was measured as lysis of erythrocytes by fecal water.', 'To quantify hemolysis in the presence of fecal water, a method was developed which measures Fe-release using atomic absorption spectrophotometry.', 'This method proved to be superior to the cell-counter method published earlier.', 'Our results showed that steroid supplementation increased, in a dose-dependent manner, the total fecal and the soluble bile acid concentration as well as lytic activity of fecal water and colonic proliferation.', 'A highly significant correlation between lytic activity of fecal water and colonic proliferation (r = 0.85, n = 24, P less than 0.001) was observed.', 'These results indicate that the increase in colonic proliferation is mediated by diet-dependent increases in soluble colonic bile acid concentration and luminal lytic activity.', 'This sequence of effects illustrates how diet could influence the risk for colon cancer.']\n",
      "Labels: tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "PMID: 32550689\n",
      "Sentences: ['The diagnosis of atopic dermatitis (AD) remains primarily a clinical diagnosis, in which several clinical signs and symptoms including pruritus, the presence and location of skin lesions, and a personal or family history of atopic conditions are used to facilitate a diagnosis.', 'In recent decades, several well-established sets of criteria have been developed to aid diagnosis.', 'With increased awareness of AD and the recent development of systemic immunomodulators to treat the condition, there exists a need to further define and consolidate the current diagnostic criteria while refining our current understanding of the clinical features of AD.', 'We propose a novel, simplified set of criteria that comprises the clinical features generally considered to be essential for a confirmed diagnosis of AD, together with features previously regarded as having less clinical significance.', 'It is essential, however, that any refinements to the diagnostic criteria for AD are made alongside regular updates of treatment guidelines so that these also reflect current developments.', 'In this regard, the current guidelines in the United States are lacking and should be updated.', 'J Drugs Dermatol.', '2020;19(3): doi:10.36849/JDD.2020.4737 THIS ARTICLE HAD BEEN MADE AVAILABLE FREE OF CHARGE.', 'PLEASE SCROLL DOWN TO ACCESS THE FULL TEXT OF THIS ARTICLE WITHOUT LOGGING IN.', 'NO PURCHASE NECESSARY.', 'PLEASE CONTACT THE PUBLISHER WITH ANY QUESTIONS.']\n",
      "Labels: tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "PMID: 26296114\n",
      "Sentences: ['In Wolf-Rayet and asymptotic giant branch (AGB) stars, the (26g)Al(p,γ)(27)Si reaction is expected to govern the destruction of the cosmic γ-ray emitting nucleus (26)Al.', 'The rate of this reaction, however, is highly uncertain due to the unknown properties of key resonances in the temperature regime of hydrogen burning.', 'We present a high-resolution inverse kinematic study of the (26g)Al(d,p)(27)Al reaction as a method for constraining the strengths of key astrophysical resonances in the (26g)Al(p,γ)(27)Si reaction.', 'In particular, the results indicate that the resonance at E(r)=127\\u2009\\u2009keV in (27)Si determines the entire (26g)Al(p,γ)(27)Si reaction rate over almost the complete temperature range of Wolf-Rayet stars and AGB stars.']\n",
      "Labels: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "dataset = SentenceLabelDataset(\"training_data.jsonl\")\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# test\n",
    "for batch in dataloader:\n",
    "    for sample in batch:\n",
    "        print(\"PMID:\", sample['pmid'])\n",
    "        print(\"Sentences:\", sample['sentences'])\n",
    "        print(\"Labels:\", sample['labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef54228-61a7-452b-8898-cc98f4b4aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "class SentenceEncoder:\n",
    "    def __init__(self, model_name=\"michiyasunaga/BioLinkBERT-base\", device=None):\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def encode(self, sentence_list):\n",
    "        \"\"\"\n",
    "        Input: a list of sentences (str), length N\n",
    "        Output: a Tensor (N, hidden_dim)\n",
    "        \"\"\"\n",
    "        embeddings = self.model.encode(\n",
    "            sentence_list, \n",
    "            convert_to_tensor=True, \n",
    "            device=self.device,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "        return embeddings  # shape: (N, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7edef494-1bff-4155-8823-1f1a8607631a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name michiyasunaga/BioLinkBERT-base. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935ac46ab534434697fc84566fc23bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/559 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43039d0ad5314bc39ee4c848184ee159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf1a786c00b4152ab746e19f01ee769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/379 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fb6504cf26480aa42ef4088fb202ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee502189be048eebbafbe0ddf4f2b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/225k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4678f2aaac5240f0b7ff50e65b8deaf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/447k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c6969323ea4f9299f21eedab378ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence count： 2\n",
      "embedding shape: torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "encoder = SentenceEncoder()\n",
    "\n",
    "# get one abstract\n",
    "for batch in dataloader:\n",
    "    sample = batch[0]  # the first abstract\n",
    "    sents = sample[\"sentences\"]\n",
    "    labels = sample[\"labels\"]\n",
    "    \n",
    "    embeddings = encoder.encode(sents)\n",
    "    print(\"sentence count：\", len(sents))\n",
    "    print(\"embedding shape:\", embeddings.shape)  # (num_sentences, hidden_dim)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f94798e-ba64-453c-b612-a4a5ef594351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=768, hidden_dim=256, num_layers=1, dropout=0.2):\n",
    "        super(SentenceClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Attention layer\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)  # output shape: (batch, sent, 1)\n",
    "\n",
    "        # Binary classifier per sentence\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, sentence_embeddings, attention_mask=None):\n",
    "        \"\"\"\n",
    "        sentence_embeddings: Tensor (num_sents, hidden_dim) — one abstract\n",
    "        attention_mask: Optional (num_sents,) — 1 for valid sentence, 0 for padding\n",
    "        \"\"\"\n",
    "        # input shape: batch = 1\n",
    "        x = sentence_embeddings.unsqueeze(0)  # (1, num_sents, input_dim)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)  # (1, num_sents, hidden_dim*2)\n",
    "\n",
    "        # Attention weight calculation\n",
    "        attn_scores = self.attention(lstm_out).squeeze(-1)  # (1, num_sents)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)    # (1, num_sents)\n",
    "\n",
    "        weighted = lstm_out.squeeze(0)  # (num_sents, hidden_dim*2)\n",
    "\n",
    "        logits = self.classifier(weighted).squeeze(-1)  # (num_sents,)\n",
    "        probs = torch.sigmoid(logits)  # binary probability\n",
    "\n",
    "        return probs, attn_weights.squeeze(0)  # Return predicted and attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f379c289-ebfd-4582-bfe0-12eccfc0a9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive Probability: tensor([0.4806, 0.4686], device='cuda:0')\n",
      "Real label: tensor([0., 0.], device='cuda:0')\n",
      "attention weight: tensor([0.4934, 0.5066], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = SentenceClassifier(input_dim=768).to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_embeds = encoder.encode(sample[\"sentences\"]).to(\"cuda\")\n",
    "    labels = sample[\"labels\"].to(\"cuda\")\n",
    "\n",
    "    probs, attn = model(sample_embeds)\n",
    "\n",
    "    print(\"Predictive Probability:\", probs)\n",
    "    print(\"Real label:\", labels)\n",
    "    print(\"attention weight:\", attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da2c22dc-9331-499f-aa15-3051bb0b9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_one_epoch(model, dataloader, encoder, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        for sample in batch:\n",
    "            sents = sample['sentences']\n",
    "            labels = sample['labels'].to(device)\n",
    "\n",
    "            embeddings = encoder.encode(sents).to(device)  # (num_sents, 768)\n",
    "            preds, _ = model(embeddings)  # (num_sents,)\n",
    "\n",
    "            if preds.shape != labels.shape:\n",
    "                print(\"Shape mismatch:\", preds.shape, labels.shape)\n",
    "                continue\n",
    "\n",
    "            loss = loss_fn(preds, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, encoder, loss_fn, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        for sample in batch:\n",
    "            sents = sample['sentences']\n",
    "            labels = sample['labels'].to(device)\n",
    "\n",
    "            embeddings = encoder.encode(sents).to(device)\n",
    "            preds, _ = model(embeddings)\n",
    "\n",
    "            loss = loss_fn(preds, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            bin_preds = (preds > 0.5).long().cpu().tolist()\n",
    "            all_preds.extend(bin_preds)\n",
    "            all_labels.extend(labels.long().cpu().tolist())\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    return total_loss / len(dataloader), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80cd3d14-90ae-40c8-9d56-3656c40f7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def train_loop(model, encoder, train_loader, val_loader, device, epochs=5, lr=2e-5, save_path=\"best_model.pt\"):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, encoder, optimizer, loss_fn, device)\n",
    "        val_loss, val_f1 = evaluate(model, val_loader, encoder, loss_fn, device)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Save best\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Best model saved at epoch {epoch+1} with F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a71a706-c878-40e5-87ba-38f42454f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "def split_dataset(dataset, val_ratio=0.1, seed=42):\n",
    "    total = len(dataset)\n",
    "    indices = list(range(total))\n",
    "    random.seed(seed)\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    split = int(total * (1 - val_ratio))\n",
    "    train_indices = indices[:split]\n",
    "    val_indices = indices[split:]\n",
    "\n",
    "    train_set = Subset(dataset, train_indices)\n",
    "    val_set = Subset(dataset, val_indices)\n",
    "\n",
    "    return train_set, val_set\n",
    "\n",
    "def build_dataloaders(jsonl_path, batch_size=4, val_ratio=0.1):\n",
    "    dataset = SentenceLabelDataset(jsonl_path)\n",
    "    train_set, val_set = split_dataset(dataset, val_ratio=val_ratio)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab713e07-1db8-4d3c-a737-cc8982b339e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = build_dataloaders(\n",
    "    jsonl_path=\"training_data.jsonl\",\n",
    "    batch_size=4,\n",
    "    val_ratio=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad553374-321b-4ebe-88d8-2dc9e7625b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name michiyasunaga/BioLinkBERT-base. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 2.0581 | Val Loss: 1.7789 | Val F1: 0.8415\n",
      "Best model saved at epoch 1 with F1: 0.8415\n",
      "Epoch 2/10\n",
      "Train Loss: 1.6356 | Val Loss: 1.6113 | Val F1: 0.8467\n",
      "Best model saved at epoch 2 with F1: 0.8467\n",
      "Epoch 3/10\n",
      "Train Loss: 1.5037 | Val Loss: 1.5396 | Val F1: 0.8506\n",
      "Best model saved at epoch 3 with F1: 0.8506\n",
      "Epoch 4/10\n",
      "Train Loss: 1.4223 | Val Loss: 1.4969 | Val F1: 0.8625\n",
      "Best model saved at epoch 4 with F1: 0.8625\n",
      "Epoch 5/10\n",
      "Train Loss: 1.3654 | Val Loss: 1.4930 | Val F1: 0.8527\n",
      "Epoch 6/10\n",
      "Train Loss: 1.3158 | Val Loss: 1.4551 | Val F1: 0.8672\n",
      "Best model saved at epoch 6 with F1: 0.8672\n",
      "Epoch 7/10\n",
      "Train Loss: 1.2710 | Val Loss: 1.4172 | Val F1: 0.8684\n",
      "Best model saved at epoch 7 with F1: 0.8684\n",
      "Epoch 8/10\n",
      "Train Loss: 1.2335 | Val Loss: 1.4205 | Val F1: 0.8677\n",
      "Epoch 9/10\n",
      "Train Loss: 1.1989 | Val Loss: 1.4199 | Val F1: 0.8673\n",
      "Epoch 10/10\n",
      "Train Loss: 1.1641 | Val Loss: 1.4179 | Val F1: 0.8672\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SentenceClassifier().to(device)\n",
    "encoder = SentenceEncoder(device=device)\n",
    "\n",
    "train_loop(\n",
    "    model=model,\n",
    "    encoder=encoder,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    epochs=10,\n",
    "    lr=2e-5,\n",
    "    save_path=\"best_finding_model.pt\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
