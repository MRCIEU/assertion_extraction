{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d7ffa9-12c6-4d57-b839-744adb81cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e36cd8-15db-423a-a2ce-7d528cbb820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 693 tagged abstracts.\n",
      "       PMID                                           Abstract Status\n",
      "0   8057077  Inward rectifier (IR) K+ channels of bovine pu...  valid\n",
      "1  27168519  Self-harm (SH; intentional self-poisoning or s...  valid\n",
      "2  20203436  Fecal samples from Ruddy Shelduck, Tadorna fer...  valid\n",
      "3  27353385  Young women, especially adolescents, often lac...  valid\n",
      "4  34657444                                [Figure: see text].  valid\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../02_extract_results_CITATIONS/raw_abstracts.csv\")\n",
    "print(f\"Loaded {len(df)} tagged abstracts.\")\n",
    "print(df.head())\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# Load API key from environment\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aebbfd4-400d-4984-a03d-860ac00e653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a biomedical expert. Given a full abstract, identify the sentence(s)\n",
    "that clearly describe the key factual findings or results of the study.\n",
    "Do not label background, objectives, methods, or interpretative statements.\n",
    "Return each result sentence exactly as it appears, one per line.\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(text):\n",
    "    return f\"\"\"\n",
    "Below is a biomedical abstract. Identify and return only the factual result sentences.\n",
    "Return each sentence exactly as it appears, one per line.\n",
    "\n",
    "{text}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310eae66-f216-43ba-b58e-6ac9f693738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gpt(abstract, max_retries=3, pause=2):\n",
    "    prompt = build_prompt(abstract)\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\",  \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\",    \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=512,\n",
    "            )\n",
    "            txt = resp.choices[0].message.content.strip()\n",
    "            # Filter out apology\n",
    "            if txt.lower().startswith((\"i'm sorry\",\"sorry\",\"unfortunately\")):\n",
    "                return \"\", 0\n",
    "            lines = [L.strip() for L in txt.split(\"\\n\") if L.strip()]\n",
    "            return \"\\n\".join(lines), len(lines)\n",
    "        except Exception as e:\n",
    "            print(f\" GPT retry {i+1}/{max_retries} failed: {e}\")\n",
    "            time.sleep(pause)\n",
    "    return \"\", 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c691ef-cfd9-4a62-a1e8-42ba69f9f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    paras = re.split(r'\\n+', text)\n",
    "    sents = []\n",
    "    for p in paras:\n",
    "        parts = re.split(r'(?<=[\\.!?])\\s+(?=[A-Z0-9])', p)\n",
    "        sents.extend(parts)\n",
    "    return [s.strip() for s in sents if s.strip()]\n",
    "\n",
    "\n",
    "import string\n",
    "def normalize(s):\n",
    "    return s.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).strip()\n",
    "\n",
    "def close_match(s, candidates, thresh=0.6):\n",
    "    s_norm = normalize(s)\n",
    "    for c in candidates:\n",
    "        c_norm = normalize(c)\n",
    "        if s_norm in c_norm or c_norm in s_norm:\n",
    "            return True\n",
    "        if SequenceMatcher(None, s_norm, c_norm).ratio() >= thresh:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64137f86-3a12-4a1a-aaa3-60ec2fb70a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying GPT: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 693/693 [27:49<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Querying GPT\"):\n",
    "    pmid     = row[\"PMID\"]\n",
    "    abstract = row[\"Abstract\"]\n",
    "    gpt_out, gpt_count = query_gpt(abstract)\n",
    "    gpt_lines = [L.lstrip(\"-–— \").strip() for L in gpt_out.split(\"\\n\") if L.strip()]\n",
    "\n",
    "    tagged_lines = []\n",
    "    for sent in split_sentences(abstract):\n",
    "        if close_match(sent, gpt_lines):\n",
    "            tagged_lines.append(f\"[GPT] {sent}\")\n",
    "        else:\n",
    "            tagged_lines.append(sent)\n",
    "\n",
    "    tagged_abstract = \" \".join(tagged_lines)\n",
    "    tag_count = tagged_abstract.count(\"[GPT]\")\n",
    "\n",
    "    results.append({\n",
    "        \"PMID\": pmid,\n",
    "        \"Abstract\": abstract,\n",
    "        \"GPT_Result_Sentences\": gpt_out,\n",
    "        \"GPT_Count\": gpt_count,\n",
    "        \"Tagged_Abstract\": tagged_abstract,\n",
    "        \"Tagged_Count\": tag_count\n",
    "    })\n",
    "    time.sleep(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab7e9d7-7ca7-45e2-964e-99956a267d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated_results.csv\n",
      "       PMID  GPT_Count  Tagged_Count\n",
      "0   8057077          6             6\n",
      "1  27168519          6             5\n",
      "2  20203436          3             3\n",
      "3  27353385          6             6\n",
      "4  34657444          1             1\n",
      "Approx match rate: Precision-like = 1.001\n"
     ]
    }
   ],
   "source": [
    "df_out = pd.DataFrame(results)\n",
    "df_out.to_csv(\"annotated_results.csv\", index=False)\n",
    "print(\"Saved annotated_results.csv\")\n",
    "\n",
    "print(df_out[[\"PMID\",\"GPT_Count\",\"Tagged_Count\"]].head())\n",
    "\n",
    "avg_prec = (df_out[\"Tagged_Count\"] / df_out[\"GPT_Count\"].replace(0,1)).mean()\n",
    "avg_recall = (df_out[\"Tagged_Count\"] / df_out[\"GPT_Count\"].replace(1,1)).mean()\n",
    "print(f\"Approx match rate: Precision-like = {avg_prec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6029bb7a-eab0-4b6f-8119-620a89e92b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 693 rows to targeted_abstract_gpt.csv\n"
     ]
    }
   ],
   "source": [
    "df_targeted = df_out[[\"PMID\", \"Tagged_Abstract\"]].rename(\n",
    "    columns={\"Tagged_Abstract\": \"Targeted_Abstract\"}\n",
    ")\n",
    "\n",
    "df_targeted.to_csv(\"targeted_abstracts_gpt.csv\", index=False)\n",
    "print(f\"Wrote {len(df_targeted)} rows to targeted_abstract_gpt.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
